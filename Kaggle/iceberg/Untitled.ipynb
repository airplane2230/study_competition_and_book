{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "# 20% 샘플을 뽑고,\n",
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "# 위에서 뽑힌 샘플을 제거해서 훈련 데이터셋으로 활용합니다.\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=41>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=112>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=268>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=172>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Normalization layer 정의\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # 적용할 열만 가져옵니다.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # 데이터의 통계치 학습\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # 정규화 진행\n",
    "    encoded_feature = normalizer(feature)\n",
    "    \n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_string_categorical_feature(feature, name, dataset):\n",
    "    # 문자열로 되어 있는 값을 integer 형태로 변환하기 위한 StringLookup() 함수 정의\n",
    "    index = StringLookup()\n",
    "    # one-hot encoding 진행을 위한 함수 정의\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "    \n",
    "    # 적용할 열만 가져옵니다.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "    \n",
    "    # 전체 순서: index adapt -> index 형태로 변환 -> categorical encoding adapt -> categorical 형태로 변환\n",
    "    \n",
    "    # feature_ds가 반환하는 문자열 데이터가 어떤 것이 있는지 확인합니다.\n",
    "    # 문자열로 된 값과, integer index를 부여하기 위한 작업입니다.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # (실제 반환 데이터) integer 형태로 변환합니다.\n",
    "    encoded_feature = index(feature)\n",
    "    \n",
    "    # Dataset 객체가 index 변환 작업을 수행하도록 적용해줍니다.\n",
    "    feature_ds = feature_ds.map(index)\n",
    "    \n",
    "    # feature_ds가 반환하는 index 데이터가 어떤 것이 있는지 확인합니다.\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # (실제 반환 데이터) one-hot encoding을 적용하고 return합니다.\n",
    "    # 데이터셋 객체에 다시 map 해줄 필요는 없습니다.\n",
    "    encoded_feature = encoder(encoded_feature)\n",
    "    \n",
    "    return encoded_feature\n",
    "\n",
    "# 위와 동일\n",
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical -> one-hot encoding\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# String -> one-hot encoding\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [sex, cp, fbs,\n",
    "                restecg, exang, ca,\n",
    "                thal, age, trestbps,\n",
    "                chol, thalach, oldpeak,slope]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_integer_categorical_feature(sex, \"sex\", train_ds)\n",
    "cp_encoded = encode_integer_categorical_feature(cp, \"cp\", train_ds)\n",
    "fbs_encoded = encode_integer_categorical_feature(fbs, \"fbs\", train_ds)\n",
    "restecg_encoded = encode_integer_categorical_feature(restecg, \"restecg\", train_ds)\n",
    "exang_encoded = encode_integer_categorical_feature(exang, \"exang\", train_ds)\n",
    "ca_encoded = encode_integer_categorical_feature(ca, \"ca\", train_ds)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_string_categorical_feature(thal, \"thal\", train_ds)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.7861 - accuracy: 0.4711 - val_loss: 0.7939 - val_accuracy: 0.3443\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7517 - accuracy: 0.4959 - val_loss: 0.7221 - val_accuracy: 0.4754\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7027 - accuracy: 0.5744 - val_loss: 0.6626 - val_accuracy: 0.5738\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6572 - accuracy: 0.6198 - val_loss: 0.6132 - val_accuracy: 0.7213\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6376 - accuracy: 0.6488 - val_loss: 0.5735 - val_accuracy: 0.7541\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5971 - accuracy: 0.7066 - val_loss: 0.5412 - val_accuracy: 0.7541\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5584 - accuracy: 0.7190 - val_loss: 0.5136 - val_accuracy: 0.7541\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.7686 - val_loss: 0.4895 - val_accuracy: 0.7869\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5192 - accuracy: 0.7645 - val_loss: 0.4691 - val_accuracy: 0.7869\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4916 - accuracy: 0.7645 - val_loss: 0.4517 - val_accuracy: 0.7869\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.7769 - val_loss: 0.4384 - val_accuracy: 0.7869\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.7851 - val_loss: 0.4258 - val_accuracy: 0.7869\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8182 - val_loss: 0.4158 - val_accuracy: 0.7869\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.8099 - val_loss: 0.4072 - val_accuracy: 0.7869\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8182 - val_loss: 0.4005 - val_accuracy: 0.7869\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8140 - val_loss: 0.3958 - val_accuracy: 0.7869\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8017 - val_loss: 0.3920 - val_accuracy: 0.8033\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.8595 - val_loss: 0.3885 - val_accuracy: 0.8033\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8017 - val_loss: 0.3848 - val_accuracy: 0.8033\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3646 - accuracy: 0.8430 - val_loss: 0.3823 - val_accuracy: 0.8033\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3709 - accuracy: 0.8264 - val_loss: 0.3806 - val_accuracy: 0.8033\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.7934 - val_loss: 0.3800 - val_accuracy: 0.8197\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8636 - val_loss: 0.3798 - val_accuracy: 0.8197\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3381 - accuracy: 0.8430 - val_loss: 0.3785 - val_accuracy: 0.8197\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.8595 - val_loss: 0.3784 - val_accuracy: 0.8197\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3751 - accuracy: 0.8430 - val_loss: 0.3787 - val_accuracy: 0.8361\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.8512 - val_loss: 0.3787 - val_accuracy: 0.8361\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8595 - val_loss: 0.3786 - val_accuracy: 0.8361\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3381 - accuracy: 0.8471 - val_loss: 0.3774 - val_accuracy: 0.8361\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8471 - val_loss: 0.3769 - val_accuracy: 0.8361\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3023 - accuracy: 0.8760 - val_loss: 0.3779 - val_accuracy: 0.8361\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.8595 - val_loss: 0.3784 - val_accuracy: 0.8197\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3258 - accuracy: 0.8182 - val_loss: 0.3799 - val_accuracy: 0.8197\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3215 - accuracy: 0.8595 - val_loss: 0.3809 - val_accuracy: 0.8197\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.8719 - val_loss: 0.3816 - val_accuracy: 0.8197\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3266 - accuracy: 0.8678 - val_loss: 0.3815 - val_accuracy: 0.8197\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8678 - val_loss: 0.3817 - val_accuracy: 0.8197\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2950 - accuracy: 0.8719 - val_loss: 0.3826 - val_accuracy: 0.8197\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2986 - accuracy: 0.8595 - val_loss: 0.3833 - val_accuracy: 0.8197\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.8430 - val_loss: 0.3838 - val_accuracy: 0.8197\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2727 - accuracy: 0.8843 - val_loss: 0.3840 - val_accuracy: 0.8197\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2936 - accuracy: 0.8678 - val_loss: 0.3844 - val_accuracy: 0.8197\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.8843 - val_loss: 0.3849 - val_accuracy: 0.8197\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2936 - accuracy: 0.8802 - val_loss: 0.3855 - val_accuracy: 0.8197\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2795 - accuracy: 0.8678 - val_loss: 0.3867 - val_accuracy: 0.8197\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2921 - accuracy: 0.8760 - val_loss: 0.3879 - val_accuracy: 0.8197\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2797 - accuracy: 0.8884 - val_loss: 0.3877 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2854 - accuracy: 0.8884 - val_loss: 0.3876 - val_accuracy: 0.8197\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.8678 - val_loss: 0.3878 - val_accuracy: 0.8197\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2921 - accuracy: 0.8760 - val_loss: 0.3874 - val_accuracy: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16322887940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, \n",
    "          epochs=50, \n",
    "          validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This particular patient had a 20.8 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.207659]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "data = np.array([[i] for i in range(50)])\n",
    "targets = np.array([[i] for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=10,batch_size= 32,\n",
    "                              sampling_rate = 1)\n",
    "\n",
    "batch_0 = data_gen[0]\n",
    "x, y = batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
