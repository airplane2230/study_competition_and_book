{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빙산인가? 선박인가? - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 (1283, 75, 75, 3) 레이블 (1283,)\n",
      "검증 데이터 (321, 75, 75, 3) 레이블 (321,)\n",
      "입사각 훈련 데이터 (1283,) 검증 데이터 (321,)\n",
      "테스트 데이터 (8424, 75, 75, 3) 입사각 테스트 데이터 (8424,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 캐글 노트북에서 진행할 경우, 4.3.1절을 참고하세요.\n",
    "DATA_PATH = './data/'\n",
    "\n",
    "train = pd.read_json(os.path.join(DATA_PATH, 'train.json'))\n",
    "test = pd.read_json(os.path.join(DATA_PATH, 'test.json'))\n",
    "\n",
    "# (75, 75)의 형태로 변경해줍니다.\n",
    "band_1 = np.array([np.array(band).reshape(75, 75) for band in train['band_1']])\n",
    "band_2 = np.array([np.array(band).reshape(75, 75) for band in train['band_2']])\n",
    "\n",
    "def get_mean_std(array):\n",
    "    return np.mean(array), np.std(array)\n",
    "\n",
    "band_1_mean, band_1_std = get_mean_std(band_1)\n",
    "band_2_mean, band_2_std = get_mean_std(band_2)\n",
    "\n",
    "# 각 이미지별로 표준화를 적용합니다.\n",
    "band_1_st = (band_1 - band_1_mean) / band_1_std\n",
    "band_2_st = (band_2 - band_2_mean) / band_2_std\n",
    "\n",
    "x_train = np.concatenate([band_1_st[:, :, :, np.newaxis], band_2_st[:, :, :, np.newaxis],\n",
    "                          ((band_1_st+band_2_st)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "train['inc_angle'] = train['inc_angle'].replace('na', 0)\n",
    "x_angle_train = np.array(train['inc_angle'])\n",
    "\n",
    "y_train = np.array(train['is_iceberg'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련/검증 데이터를 0.7/0.3의 비율로 분리합니다.\n",
    "x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(x_train, x_angle_train, y_train, \n",
    "                                                                              test_size = 0.2, random_state = 777)\n",
    "\n",
    "# 평가에 사용할 테스트 데이터를 만듭니다.\n",
    "test_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "test_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "\n",
    "test_band_1_st = (test_band_1 - band_1_mean) / band_1_std\n",
    "test_band_2_st = (test_band_2 - band_2_mean) / band_2_std\n",
    "\n",
    "x_test = np.concatenate([test_band_1_st[:, :, :, np.newaxis]\n",
    "                          , test_band_2_st[:, :, :, np.newaxis]\n",
    "                         , ((test_band_1_st+test_band_2_st)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "x_angle_test = np.array(test['inc_angle'])\n",
    "\n",
    "\n",
    "print('훈련 데이터 {} 레이블 {}'.format(str(x_train.shape), str(y_train.shape)))\n",
    "print('검증 데이터 {} 레이블 {}'.format(str(x_val.shape), str(y_val.shape)))\n",
    "print('입사각 훈련 데이터 {} 검증 데이터 {}'.format(str(x_angle_train.shape), str(x_angle_val.shape)))\n",
    "print('테스트 데이터 {} 입사각 테스트 데이터 {}'.format(str(x_test.shape), str(x_angle_test.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 25s 0us/step\n",
      "model ready ~\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_model():\n",
    "    # 이미지 입력\n",
    "    img_input = Input(shape=(75, 75, 3), name=\"img\")\n",
    "    # 입사각 입력\n",
    "    angle_input = Input(shape=[1], name=\"angle\")\n",
    "    \n",
    "    # 이미지의 입력을 다룹니다.\n",
    "    base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (75, 75, 3))(img_input)\n",
    "    img_x = GlobalAveragePooling2D()(base_model)\n",
    "    img_x = Dense(512, activation = 'relu')(img_x)\n",
    "    img_x = Dropout(0.5)(img_x)\n",
    "    img_x = Dense(256, activation = 'relu')(img_x)\n",
    "    img_x = Dropout(0.5)(img_x)\n",
    "    img_x = Dense(128, activation = 'relu')(img_x)\n",
    "    img_x = Dropout(0.3)(img_x)\n",
    "    \n",
    "    # 입사각의 입력을 이미지를 분석한 층과 합칩니다.\n",
    "    angle_concat = Concatenate()([img_x, angle_input])\n",
    "    \n",
    "    x = Dense(64, activation = 'relu')(angle_concat)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # 출력값을 만듭니다. \n",
    "    output = Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs = [img_input, angle_input], outputs = output)\n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss = 'binary_crossentropy',\n",
    "                 metrics = ['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "print('model ready ~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1283 samples, validate on 321 samples\n",
      "Epoch 1/30\n",
      "1283/1283 [==============================] - 30s 24ms/sample - loss: 0.8628 - acc: 0.5916 - val_loss: 54582.2854 - val_acc: 0.5202\n",
      "Epoch 2/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.6542 - acc: 0.6399 - val_loss: 123.6341 - val_acc: 0.5202\n",
      "Epoch 3/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.5082 - acc: 0.7428 - val_loss: 0.6501 - val_acc: 0.5732\n",
      "Epoch 4/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.4426 - acc: 0.8153 - val_loss: 77.3480 - val_acc: 0.5202\n",
      "Epoch 5/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.4114 - acc: 0.8239 - val_loss: 495.5134 - val_acc: 0.5202\n",
      "Epoch 6/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.3247 - acc: 0.8730 - val_loss: 159.7382 - val_acc: 0.5202\n",
      "Epoch 7/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.3982 - acc: 0.8644 - val_loss: 0.6748 - val_acc: 0.5888\n",
      "Epoch 8/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.3023 - acc: 0.8971 - val_loss: 0.6669 - val_acc: 0.5919\n",
      "Epoch 9/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.2272 - acc: 0.9228 - val_loss: 0.7888 - val_acc: 0.5732\n",
      "Epoch 10/30\n",
      "1283/1283 [==============================] - 8s 7ms/sample - loss: 0.2107 - acc: 0.9345 - val_loss: 0.9825 - val_acc: 0.5732\n",
      "Epoch 11/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.2148 - acc: 0.9236 - val_loss: 0.9097 - val_acc: 0.5732\n",
      "Epoch 12/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1571 - acc: 0.9564 - val_loss: 0.9967 - val_acc: 0.5826\n",
      "Epoch 13/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1330 - acc: 0.9641 - val_loss: 0.9849 - val_acc: 0.6168\n",
      "Epoch 14/30\n",
      "1283/1283 [==============================] - 8s 7ms/sample - loss: 0.1216 - acc: 0.9704 - val_loss: 0.9437 - val_acc: 0.6293\n",
      "Epoch 15/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1127 - acc: 0.9719 - val_loss: 0.9231 - val_acc: 0.6542\n",
      "Epoch 16/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1234 - acc: 0.9727 - val_loss: 0.8938 - val_acc: 0.6791\n",
      "Epoch 17/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1102 - acc: 0.9735 - val_loss: 0.8616 - val_acc: 0.6916\n",
      "Epoch 18/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1076 - acc: 0.9719 - val_loss: 0.7873 - val_acc: 0.7072\n",
      "Epoch 19/30\n",
      "1283/1283 [==============================] - 8s 6ms/sample - loss: 0.1066 - acc: 0.9751 - val_loss: 0.6838 - val_acc: 0.7508\n",
      "Epoch 20/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1030 - acc: 0.9751 - val_loss: 0.5827 - val_acc: 0.7975\n",
      "Epoch 21/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1054 - acc: 0.9719 - val_loss: 0.4825 - val_acc: 0.8287\n",
      "Epoch 22/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.0992 - acc: 0.9805 - val_loss: 0.4201 - val_acc: 0.8380\n",
      "Epoch 23/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1065 - acc: 0.9719 - val_loss: 0.3879 - val_acc: 0.8536\n",
      "Epoch 24/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1171 - acc: 0.9743 - val_loss: 0.3770 - val_acc: 0.8536\n",
      "Epoch 25/30\n",
      "1283/1283 [==============================] - 10s 7ms/sample - loss: 0.1101 - acc: 0.9704 - val_loss: 0.3715 - val_acc: 0.8567\n",
      "Epoch 26/30\n",
      "1283/1283 [==============================] - 10s 7ms/sample - loss: 0.1284 - acc: 0.9766 - val_loss: 0.3674 - val_acc: 0.8660\n",
      "Epoch 27/30\n",
      "1283/1283 [==============================] - 10s 8ms/sample - loss: 0.0993 - acc: 0.9758 - val_loss: 0.3629 - val_acc: 0.8723\n",
      "Epoch 28/30\n",
      "1283/1283 [==============================] - 10s 8ms/sample - loss: 0.0994 - acc: 0.9774 - val_loss: 0.3581 - val_acc: 0.8723\n",
      "Epoch 29/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1052 - acc: 0.9727 - val_loss: 0.3542 - val_acc: 0.8723\n",
      "Epoch 30/30\n",
      "1283/1283 [==============================] - 9s 7ms/sample - loss: 0.1152 - acc: 0.9766 - val_loss: 0.3511 - val_acc: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21864f3d710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "filepath = './model'\n",
    "\n",
    "if(not os.path.exists(filepath)):\n",
    "    os.mkdir(filepath)\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath + '/best_model.hdf5', save_best_only = True, verbose = 1),\n",
    "            ReduceLROnPlateau(monitor = 'val_loss', patience = 5)]\n",
    "\n",
    "model.fit([x_train, x_angle_train], y_train, epochs = 30,\n",
    "         validation_data = ([x_val, x_angle_val], y_val),\n",
    "         batch_size = 32,\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./path.hdf5') # 모델을 저장합니다.\n",
    "\n",
    "model.load_weights('./path.hdf5') # 모델의 가중치만 볼러옵니다.\n",
    "\n",
    "model.load_model('./path.hdf5') # 모델의 구조와 가중치를 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 가중치만 불러옵니다.\n",
    "model.load_weights(filepath + '/best_model.hdf5')\n",
    "\n",
    "predicted_test = model.predict([x_test, x_angle_test])\n",
    "\n",
    "# 캐글에 제출할 형식을 만듭니다.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
